"""
run_pipeline.py
é©±åŠ¨æ•´ä¸ª K çº¿åˆ†ææµæ°´çº¿çš„å…¥å£è„šæœ¬ã€‚

æµç¨‹:
1. åŠ è½½æ•°æ®    - ä½¿ç”¨ data_loader è‡ªåŠ¨é€‚é…æ•°æ®æº
2. å¤„ç†åŸå§‹Kçº¿ - æ·»åŠ  K çº¿çŠ¶æ€æ ‡ç­¾
3. Kçº¿åˆå¹¶     - åˆå¹¶åŒ…å«å…³ç³»çš„ K çº¿
4. åˆ†å‹è¯†åˆ«    - è¯†åˆ«åˆ†å‹å¹¶è¿‡æ»¤ç”Ÿæˆæœ‰æ•ˆç¬”

ç”¨æ³•:
    uv run run_pipeline.py              # äº¤äº’å¼é€‰æ‹©æ•°æ®æ–‡ä»¶
    uv run run_pipeline.py data/raw/TL.CFE.xlsx  # ç›´æ¥æŒ‡å®šæ–‡ä»¶
    
è¾“å‡ºæ–‡ä»¶:
    - data/processed/*_processed.csv   (å¸¦çŠ¶æ€æ ‡ç­¾çš„åŸå§‹Kçº¿)
    - data/processed/*_merged.csv      (åˆå¹¶åçš„Kçº¿)
    - data/processed/*_strokes.csv     (å¸¦ç¬”ç«¯ç‚¹æ ‡è®°çš„æœ€ç»ˆç»“æœ)
    - output/*_merged_kline.png        (åˆå¹¶åKçº¿å›¾)
    - output/*_strokes.png             (ç¬”ç«¯ç‚¹æ ‡è®°å›¾)
"""

import sys
from pathlib import Path

# ç¡®ä¿ src æ¨¡å—å¯å¯¼å…¥
sys.path.insert(0, str(Path(__file__).parent))

# ç›®å½•é…ç½®
DATA_RAW_DIR = Path("data/raw")
DATA_PROCESSED_DIR = Path("data/processed")
OUTPUT_DIR = Path("output")

# æ”¯æŒçš„æ•°æ®æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = {'.xlsx', '.xls', '.csv'}


def find_data_files(directory: Path = DATA_RAW_DIR) -> list[Path]:
    """æ‰«æç›®å½•ä¸‹æ‰€æœ‰æ”¯æŒçš„æ•°æ®æ–‡ä»¶"""
    if not directory.exists():
        return []
    
    files = []
    for ext in SUPPORTED_EXTENSIONS:
        for f in directory.glob(f'*{ext}'):
            files.append(f)
    return sorted(files, key=lambda x: x.name.lower())


def select_file_interactive() -> str:
    """äº¤äº’å¼é€‰æ‹©æ•°æ®æ–‡ä»¶"""
    files = find_data_files()
    
    if not files:
        print(f"âŒ ç›®å½• '{DATA_RAW_DIR}' ä¸‹æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„æ•°æ®æ–‡ä»¶")
        print(f"   æ”¯æŒçš„æ ¼å¼: {', '.join(SUPPORTED_EXTENSIONS)}")
        print(f"   è¯·å°†æ•°æ®æ–‡ä»¶æ”¾åˆ° {DATA_RAW_DIR}/ ç›®å½•ä¸‹")
        sys.exit(1)
    
    if len(files) == 1:
        print(f"æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {files[0].name}")
        return str(files[0])
    
    print("\nğŸ“‚ è¯·é€‰æ‹©è¦å¤„ç†çš„æ•°æ®æ–‡ä»¶:\n")
    for i, f in enumerate(files, 1):
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
        size_kb = f.stat().st_size / 1024
        print(f"  [{i}] {f.name}  ({size_kb:.1f} KB)")
    
    print(f"\n  [0] é€€å‡º\n")
    
    while True:
        try:
            choice = input("è¯·è¾“å…¥åºå·: ").strip()
            if choice == '0':
                print("å·²é€€å‡º")
                sys.exit(0)
            
            idx = int(choice) - 1
            if 0 <= idx < len(files):
                selected = files[idx]
                print(f"\nâœ… å·²é€‰æ‹©: {selected.name}\n")
                return str(selected)
            else:
                print(f"è¯·è¾“å…¥ 0-{len(files)} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nå·²å–æ¶ˆ")
            sys.exit(0)


def main(input_file: str):
    print("=" * 60)
    print("K çº¿åˆ†ææµæ°´çº¿ (Bill Williams / Chan Theory)")
    print("=" * 60)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # ä»è¾“å…¥æ–‡ä»¶åç”Ÿæˆè¾“å‡ºæ–‡ä»¶åå’Œå­ç›®å½•
    input_path = Path(input_file)
    base_name = input_path.stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶åï¼Œå¦‚ "TL.CFE"
    
    # æå–tickerä½œä¸ºå­ç›®å½•åï¼ˆå–ç¬¬ä¸€ä¸ªç‚¹ä¹‹å‰çš„éƒ¨åˆ†ï¼Œè½¬å°å†™ï¼‰
    ticker = base_name.split('.')[0].lower()  # "TL.CFE" -> "tl"
    
    # åˆ›å»ºtickerå­ç›®å½•
    ticker_processed_dir = DATA_PROCESSED_DIR / ticker
    ticker_output_dir = OUTPUT_DIR / ticker
    ticker_processed_dir.mkdir(parents=True, exist_ok=True)
    ticker_output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¾“å‡ºè·¯å¾„
    processed_csv = ticker_processed_dir / f"{base_name}_processed.csv"
    merged_csv = ticker_processed_dir / f"{base_name}_merged.csv"
    strokes_csv = ticker_processed_dir / f"{base_name}_strokes.csv"
    merged_plot = ticker_output_dir / f"{base_name}_merged_kline.png"
    strokes_plot = ticker_output_dir / f"{base_name}_strokes.png"
    
    # Step 1: åŠ è½½æ•°æ®
    print(f"\n[Step 1/4] åŠ è½½æ•°æ®: {input_file}")
    from src.io import load_ohlc
    data = load_ohlc(input_file)
    print(f"  åŠ è½½å®Œæˆ: {data}")
    print(f"  æ—¥æœŸèŒƒå›´: {data.date_range[0].date()} ~ {data.date_range[1].date()}")
    
    # Step 2: å¤„ç†åŸå§‹æ•°æ®ï¼Œæ·»åŠ Kçº¿çŠ¶æ€
    print(f"\n[Step 2/4] æ·»åŠ  K çº¿çŠ¶æ€æ ‡ç­¾...")
    from src.analysis import process_and_save
    process_and_save(data, str(processed_csv))
    
    # Step 3: K çº¿åˆå¹¶
    print(f"\n[Step 3/4] åˆå¹¶åŒ…å«å…³ç³»çš„ K çº¿...")
    from src.analysis.merging import apply_kline_merging
    apply_kline_merging(str(processed_csv), str(merged_csv), 
                        save_plot_path=str(merged_plot))
    
    # Step 4: åˆ†å‹è¯†åˆ«ä¸ç¬”è¿‡æ»¤
    print(f"\n[Step 4/4] è¯†åˆ«åˆ†å‹å¹¶ç”Ÿæˆæœ‰æ•ˆç¬”...")
    from src.analysis.fractals import process_strokes
    process_strokes(str(merged_csv), str(strokes_csv),
                    save_plot_path=str(strokes_plot))

    # Step 5: ç”Ÿæˆäº¤äº’å¼å›¾è¡¨
    print(f"\n[Step 5/5] ç”Ÿæˆäº¤äº’å¼ HTML å›¾è¡¨...")
    from src.analysis import ChartBuilder, compute_ema
    interactive_plot = ticker_output_dir / f"{base_name}_interactive.html"
    
    # é‡æ–°åŠ è½½æ•°æ®ä»¥è·å–ç»˜å›¾æ‰€éœ€çš„DataFrame
    import pandas as pd
    
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨åˆå¹¶åçš„æ•°æ®æ¥ç”»å›¾ï¼Œå› ä¸ºå®ƒæ›´å¹²å‡€
    # ä½†strokesæ˜¯åŸºäºåˆå¹¶åæ•°æ®çš„ç´¢å¼•ï¼Œæ‰€ä»¥æ˜¯å¯¹é½çš„
    merged_df = pd.read_csv(merged_csv)
    # è½¬æ¢ datetime
    merged_df['datetime'] = pd.to_datetime(merged_df['datetime'])
    
    # è¯»å– strokes
    strokes_df = pd.read_csv(strokes_csv)
    # è½¬æ¢ strokes ä¸º [(idx, type)] æ ¼å¼
    stroke_list = [
        (idx, row['valid_fractal']) 
        for idx, row in strokes_df.iterrows()
        if pd.notna(row['valid_fractal'])
    ]
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    merged_df['ema20'] = compute_ema(merged_df, 20)
    
    # ä½¿ç”¨ ChartBuilder æ„å»ºå›¾è¡¨
    chart = ChartBuilder(merged_df)
    chart.add_candlestick()
    chart.add_indicator('EMA20', merged_df['ema20'], '#FFA500')  # æ©™è‰²
    chart.add_strokes(stroke_list)
    chart.add_fractal_markers(stroke_list)
    chart.build(str(interactive_plot))
    
    print("\n" + "=" * 60)
    print("æµæ°´çº¿å®Œæˆï¼")
    print("=" * 60)
    print("ç”Ÿæˆæ–‡ä»¶:")
    print(f"  CSV (data/processed/):")
    print(f"    - {processed_csv.name}  (å¸¦çŠ¶æ€æ ‡ç­¾çš„åŸå§‹Kçº¿)")
    print(f"    - {merged_csv.name}     (åˆå¹¶åçš„Kçº¿)")
    print(f"    - {strokes_csv.name}    (å¸¦ç¬”ç«¯ç‚¹æ ‡è®°çš„æœ€ç»ˆç»“æœ)")
    print(f"  å›¾è¡¨ (output/):")
    print(f"    - {merged_plot.name}  (åˆå¹¶åKçº¿å›¾)")
    print(f"    - {strokes_plot.name}       (ç¬”ç«¯ç‚¹æ ‡è®°å›¾)")
    print(f"    - {interactive_plot.name}   (äº¤äº’å¼HTMLå›¾è¡¨) ğŸ†•")


if __name__ == "__main__":
    # é»˜è®¤æ•°æ®æ–‡ä»¶
    DEFAULT_FILE = "data/raw/TB10Y.WI.xlsx"
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æˆ–äº¤äº’å¼é€‰æ‹©
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    elif sys.stdin.isatty():
        # äº¤äº’å¼ç»ˆç«¯ï¼Œè®©ç”¨æˆ·é€‰æ‹©
        input_file = select_file_interactive()
    else:
        # éäº¤äº’å¼ï¼ˆå¦‚ agent è°ƒç”¨ï¼‰ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶
        print(f"éäº¤äº’æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶: {DEFAULT_FILE}")
        input_file = DEFAULT_FILE
    
    main(input_file)
