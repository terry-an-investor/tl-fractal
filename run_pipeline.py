"""
run_pipeline.py
é©±åŠ¨æ•´ä¸ª K çº¿åˆ†ææµæ°´çº¿çš„å…¥å£è„šæœ¬ã€‚

æµç¨‹:
1. åŠ è½½æ•°æ®    - ä½¿ç”¨ data_loader è‡ªåŠ¨é€‚é…æ•°æ®æº
2. å¤„ç†åŸå§‹Kçº¿ - æ·»åŠ  K çº¿çŠ¶æ€æ ‡ç­¾
3. Kçº¿åˆå¹¶     - åˆå¹¶åŒ…å«å…³ç³»çš„ K çº¿
4. åˆ†å‹è¯†åˆ«    - è¯†åˆ«åˆ†å‹å¹¶è¿‡æ»¤ç”Ÿæˆæœ‰æ•ˆç¬”

ç”¨æ³•:
    uv run run_pipeline.py              # äº¤äº’å¼é€‰æ‹©æ•°æ®æ–‡ä»¶
    uv run run_pipeline.py data/raw/TL.CFE.xlsx  # ç›´æ¥æŒ‡å®šæ–‡ä»¶
    
è¾“å‡ºæ–‡ä»¶:
    - data/processed/*_processed.csv   (å¸¦çŠ¶æ€æ ‡ç­¾çš„åŸå§‹Kçº¿)
    - data/processed/*_merged.csv      (åˆå¹¶åçš„Kçº¿)
    - data/processed/*_strokes.csv     (å¸¦ç¬”ç«¯ç‚¹æ ‡è®°çš„æœ€ç»ˆç»“æœ)
    - output/*_merged_kline.png        (åˆå¹¶åKçº¿å›¾)
    - output/*_strokes.png             (ç¬”ç«¯ç‚¹æ ‡è®°å›¾)
"""

import sys
from pathlib import Path

# ç¡®ä¿ src æ¨¡å—å¯å¯¼å…¥
sys.path.insert(0, str(Path(__file__).parent))

# ç›®å½•é…ç½®
DATA_RAW_DIR = Path("data/raw")
DATA_PROCESSED_DIR = Path("data/processed")
OUTPUT_DIR = Path("output")

# æ”¯æŒçš„æ•°æ®æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = {'.xlsx', '.xls', '.csv'}


def find_data_files(directory: Path = DATA_RAW_DIR) -> list[Path]:
    """æ‰«æç›®å½•ä¸‹æ‰€æœ‰æ”¯æŒçš„æ•°æ®æ–‡ä»¶"""
    if not directory.exists():
        return []
    
    files = []
    for ext in SUPPORTED_EXTENSIONS:
        for f in directory.glob(f'*{ext}'):
            files.append(f)
    return sorted(files, key=lambda x: x.name.lower())


def select_file_interactive() -> str:
    """äº¤äº’å¼é€‰æ‹©æ•°æ®æ–‡ä»¶"""
    files = find_data_files()
    
    if not files:
        print(f"âŒ ç›®å½• '{DATA_RAW_DIR}' ä¸‹æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„æ•°æ®æ–‡ä»¶")
        print(f"   æ”¯æŒçš„æ ¼å¼: {', '.join(SUPPORTED_EXTENSIONS)}")
        print(f"   è¯·å°†æ•°æ®æ–‡ä»¶æ”¾åˆ° {DATA_RAW_DIR}/ ç›®å½•ä¸‹")
        sys.exit(1)
    
    if len(files) == 1:
        print(f"æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {files[0].name}")
        return str(files[0])
    
    print("\nğŸ“‚ è¯·é€‰æ‹©è¦å¤„ç†çš„æ•°æ®æ–‡ä»¶:\n")
    for i, f in enumerate(files, 1):
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
        size_kb = f.stat().st_size / 1024
        print(f"  [{i}] {f.name}  ({size_kb:.1f} KB)")
    
    print(f"\n  [0] é€€å‡º\n")
    
    while True:
        try:
            choice = input("è¯·è¾“å…¥åºå·: ").strip()
            if choice == '0':
                print("å·²é€€å‡º")
                sys.exit(0)
            
            idx = int(choice) - 1
            if 0 <= idx < len(files):
                selected = files[idx]
                print(f"\nâœ… å·²é€‰æ‹©: {selected.name}\n")
                return str(selected)
            else:
                print(f"è¯·è¾“å…¥ 0-{len(files)} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\nå·²å–æ¶ˆ")
            sys.exit(0)


def main(input_file: str):
    print("=" * 60)
    print("K çº¿åˆ†ææµæ°´çº¿ (Bill Williams / Chan Theory)")
    print("=" * 60)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # ä»è¾“å…¥æ–‡ä»¶åç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    input_path = Path(input_file)
    base_name = input_path.stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
    
    # è¾“å‡ºè·¯å¾„
    processed_csv = DATA_PROCESSED_DIR / f"{base_name}_processed.csv"
    merged_csv = DATA_PROCESSED_DIR / f"{base_name}_merged.csv"
    strokes_csv = DATA_PROCESSED_DIR / f"{base_name}_strokes.csv"
    merged_plot = OUTPUT_DIR / f"{base_name}_merged_kline.png"
    strokes_plot = OUTPUT_DIR / f"{base_name}_strokes.png"
    
    # Step 1: åŠ è½½æ•°æ®
    print(f"\n[Step 1/4] åŠ è½½æ•°æ®: {input_file}")
    from src.io import load_ohlc
    data = load_ohlc(input_file)
    print(f"  åŠ è½½å®Œæˆ: {data}")
    print(f"  æ—¥æœŸèŒƒå›´: {data.date_range[0].date()} ~ {data.date_range[1].date()}")
    
    # Step 2: å¤„ç†åŸå§‹æ•°æ®ï¼Œæ·»åŠ Kçº¿çŠ¶æ€
    print(f"\n[Step 2/4] æ·»åŠ  K çº¿çŠ¶æ€æ ‡ç­¾...")
    from src.analysis import process_and_save
    process_and_save(data, str(processed_csv))
    
    # Step 3: K çº¿åˆå¹¶
    print(f"\n[Step 3/4] åˆå¹¶åŒ…å«å…³ç³»çš„ K çº¿...")
    from src.analysis.merging import apply_kline_merging
    apply_kline_merging(str(processed_csv), str(merged_csv), 
                        save_plot_path=str(merged_plot))
    
    # Step 4: åˆ†å‹è¯†åˆ«ä¸ç¬”è¿‡æ»¤
    print(f"\n[Step 4/4] è¯†åˆ«åˆ†å‹å¹¶ç”Ÿæˆæœ‰æ•ˆç¬”...")
    from src.analysis.fractals import process_strokes
    process_strokes(str(merged_csv), str(strokes_csv),
                    save_plot_path=str(strokes_plot))
    
    print("\n" + "=" * 60)
    print("æµæ°´çº¿å®Œæˆï¼")
    print("=" * 60)
    print("ç”Ÿæˆæ–‡ä»¶:")
    print(f"  CSV (data/processed/):")
    print(f"    - {processed_csv.name}  (å¸¦çŠ¶æ€æ ‡ç­¾çš„åŸå§‹Kçº¿)")
    print(f"    - {merged_csv.name}     (åˆå¹¶åçš„Kçº¿)")
    print(f"    - {strokes_csv.name}    (å¸¦ç¬”ç«¯ç‚¹æ ‡è®°çš„æœ€ç»ˆç»“æœ)")
    print(f"  å›¾è¡¨ (output/):")
    print(f"    - {merged_plot.name}  (åˆå¹¶åKçº¿å›¾)")
    print(f"    - {strokes_plot.name}       (ç¬”ç«¯ç‚¹æ ‡è®°å›¾)")


if __name__ == "__main__":
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æˆ–äº¤äº’å¼é€‰æ‹©
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    else:
        input_file = select_file_interactive()
    
    main(input_file)
