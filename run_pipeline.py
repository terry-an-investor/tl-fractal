"""
run_pipeline.py
é©±åŠ¨æ•´ä¸ª K çº¿åˆ†ææµæ°´çº¿çš„å…¥å£è„šæœ¬ã€‚

æµç¨‹:
1. åŠ è½½æ•°æ®    - ä½¿ç”¨ data_loader è‡ªåŠ¨é€‚é…æ•°æ®æº
2. å¤„ç†åŸå§‹Kçº¿ - æ·»åŠ  K çº¿çŠ¶æ€æ ‡ç­¾
3. Kçº¿åˆå¹¶     - åˆå¹¶åŒ…å«å…³ç³»çš„ K çº¿
4. åˆ†å‹è¯†åˆ«    - è¯†åˆ«åˆ†å‹å¹¶è¿‡æ»¤ç”Ÿæˆæœ‰æ•ˆç¬”

ç”¨æ³•:
    uv run run_pipeline.py              # äº¤äº’å¼é€‰æ‹©æ•°æ®æ–‡ä»¶
    uv run run_pipeline.py data/raw/TL.CFE.xlsx  # ç›´æ¥æŒ‡å®šæ–‡ä»¶
    
è¾“å‡ºæ–‡ä»¶:
    - data/processed/*_processed.csv   (å¸¦çŠ¶æ€æ ‡ç­¾çš„åŸå§‹Kçº¿)
    - data/processed/*_merged.csv      (åˆå¹¶åçš„Kçº¿)
    - data/processed/*_strokes.csv     (å¸¦ç¬”ç«¯ç‚¹æ ‡è®°çš„æœ€ç»ˆç»“æœ)
    - output/*_merged_kline.png        (åˆå¹¶åKçº¿å›¾)
    - output/*_strokes.png             (ç¬”ç«¯ç‚¹æ ‡è®°å›¾)
"""

import sys
from pathlib import Path

# ç¡®ä¿ src æ¨¡å—å¯å¯¼å…¥
sys.path.insert(0, str(Path(__file__).parent))

# ç›®å½•é…ç½®
DATA_RAW_DIR = Path("data/raw")
DATA_PROCESSED_DIR = Path("data/processed")
OUTPUT_DIR = Path("output")

# æ”¯æŒçš„æ•°æ®æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = {'.xlsx', '.xls', '.csv'}


def find_data_files(directory: Path = DATA_RAW_DIR) -> list[Path]:
    """æ‰«æç›®å½•ä¸‹æ‰€æœ‰æ”¯æŒçš„æ•°æ®æ–‡ä»¶"""
    if not directory.exists():
        return []
    
    files = []
    for ext in SUPPORTED_EXTENSIONS:
        for f in directory.glob(f'*{ext}'):
            files.append(f)
    return sorted(files, key=lambda x: x.name.lower())


def select_file_interactive() -> list[str]:
    """äº¤äº’å¼é€‰æ‹©æ•°æ®æ–‡ä»¶ (æ”¯æŒå¤šé€‰)"""
    from src.io.data_config import DATA_SOURCES
    
    files = find_data_files()
    
    if not files:
        print(f"âŒ ç›®å½• '{DATA_RAW_DIR}' ä¸‹æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„æ•°æ®æ–‡ä»¶")
        print(f"   æ”¯æŒçš„æ ¼å¼: {', '.join(SUPPORTED_EXTENSIONS)}")
        print(f"   è¯·å°†æ•°æ®æ–‡ä»¶æ”¾åˆ° {DATA_RAW_DIR}/ ç›®å½•ä¸‹")
        sys.exit(1)
    
    if len(files) == 1:
        print(f"æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {files[0].name}")
        return [str(files[0])]
    
    # åŒºåˆ† API è·å–çš„æ–‡ä»¶å’Œç”¨æˆ·æä¾›çš„æ–‡ä»¶
    api_filenames = {cfg.filename for cfg in DATA_SOURCES}
    api_files = []
    user_files = []
    
    import re
    # åŒ¹é… Wind API è¾“å‡ºçš„æ–‡ä»¶åæ ¼å¼: ä»£ç _åç¼€.xlsx (å¦‚ 000510_SH.xlsx)
    wind_file_pattern = re.compile(r'^[a-zA-Z0-9.]+_[a-zA-Z]+\.xlsx$', re.IGNORECASE)
    
    for f in files:
        if f.name in api_filenames or wind_file_pattern.match(f.name):
            api_files.append(f)
        else:
            user_files.append(f)
            
    # åˆå¹¶åˆ—è¡¨ç”¨äºç´¢å¼•é€‰æ‹© (API åœ¨å‰)
    all_files = api_files + user_files
    
    print("\nğŸ“‚ è¯·é€‰æ‹©è¦å¤„ç†çš„æ•°æ®æ–‡ä»¶:\n")
    
    current_idx = 1
    
    if api_files:
        print("  --- ğŸŒ æ¥è‡ª Wind API ---")
        
        # å°è¯•ä¸ºä¸€ä¸ª Wind è¿æ¥å®ä¾‹åŒ–é€‚é…å™¨ (ç”¨äºè§£æåç§°)
        wind_adapter = None
        
        # è¯»å–åç§°ç¼“å­˜
        import json
        cache_data = {}
        cache_file = DATA_RAW_DIR / "security_names.json"
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
            except Exception:
                pass
        
        for f in api_files:
            size_kb = f.stat().st_size / 1024
            # æ‰¾åˆ°å¯¹åº”çš„é…ç½®åç§°
            comment = ""
            found_config = False
            for cfg in DATA_SOURCES:
                if cfg.filename == f.name:
                    comment = f"[{cfg.name}]"
                    found_config = True
                    break
            
            # å¦‚æœä¸åœ¨é…ç½®ä¸­ï¼Œå°è¯•åŠ¨æ€è§£æ
            if not found_config and wind_file_pattern.match(f.name):
                # ä»æ–‡ä»¶åè¿˜åŸ symbol
                symbol = f.stem.replace('_', '.')
                
                # 1. å°è¯•ä»ç¼“å­˜è¯»å–
                if symbol in cache_data:
                     comment = f"[{cache_data[symbol]}]"
                
                # 2. å¦‚æœç¼“å­˜æ²¡æœ‰ï¼Œæ‰ä½¿ç”¨ API å¹¶å°è¯•å®ä¾‹åŒ–é€‚é…å™¨
                else:
                    try:
                        if wind_adapter is None:
                            from src.io.adapters.wind_api_adapter import WindAPIAdapter
                            wind_adapter = WindAPIAdapter()
                        
                        name = wind_adapter.get_security_name(symbol)
                        if name != symbol:
                            comment = f"[{name}]"
                            
                            # æ›´æ–°ç¼“å­˜å¹¶ä¿å­˜
                            cache_data[symbol] = name
                            try:
                                with open(cache_file, 'w', encoding='utf-8') as f:
                                    json.dump(cache_data, f, ensure_ascii=False, indent=2)
                            except Exception:
                                pass
                    except Exception:
                        pass
            
            print(f"  [{current_idx}] {f.name:<20} {comment} ({size_kb:.1f} KB)")
            current_idx += 1
        print()
            
    if user_files:
        print("  --- ğŸ‘¤ ç”¨æˆ·æ‰‹å·¥æä¾› ---")
        for f in user_files:
            size_kb = f.stat().st_size / 1024
            print(f"  [{current_idx}] {f.name:<20} ({size_kb:.1f} KB)")
            current_idx += 1
    
    print(f"\n  [0] é€€å‡º\n")
    print(f"  æç¤º: è¾“å…¥å¤šä¸ªåºå·å¯ç”¨ç©ºæ ¼æˆ–é€—å·åˆ†éš” (å¦‚: 1 2 3)\n")
    
    while True:
        try:
            raw_input = input("è¯·è¾“å…¥åºå·: ").strip()
            if raw_input == '0':
                print("å·²é€€å‡º")
                sys.exit(0)
            
            # æ”¯æŒç©ºæ ¼æˆ–é€—å·åˆ†éš”
            parts = raw_input.replace(',', ' ').split()
            selected_files = []
            invalid_inputs = []
            
            for part in parts:
                try:
                    idx = int(part) - 1
                    if 0 <= idx < len(all_files):
                        selected_files.append(all_files[idx])
                    else:
                        invalid_inputs.append(part)
                except ValueError:
                    invalid_inputs.append(part)
            
            if invalid_inputs:
                print(f"âŒ æ— æ•ˆçš„åºå·: {', '.join(invalid_inputs)}")
                continue
                
            if not selected_files:
                print("æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶")
                continue
                
            print(f"\nâœ… å·²é€‰æ‹© {len(selected_files)} ä¸ªæ–‡ä»¶:")
            for f in selected_files:
                print(f"  - {f.name}")
            print()
            return [str(f) for f in selected_files]
            
        except KeyboardInterrupt:
            print("\nå·²å–æ¶ˆ")
            sys.exit(0)


def main(input_file: str):
    print("=" * 60)
    print("K çº¿åˆ†ææµæ°´çº¿ (Bill Williams / Chan Theory)")
    print("=" * 60)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # Step 1: åŠ è½½æ•°æ® (æå‰åˆ°è¿™é‡Œä»¥ä¾¿ä½¿ç”¨æ•°æ®ä¸­çš„åç§°æ¥åˆ›å»ºç›®å½•)
    print(f"\n[Step 1/4] åŠ è½½æ•°æ®: {input_file}")
    from src.io import load_ohlc
    data = load_ohlc(input_file)
    print(f"  åŠ è½½å®Œæˆ: {data}")
    print(f"  æ—¥æœŸèŒƒå›´: {data.date_range[0].date()} ~ {data.date_range[1].date()}")

    # ä»è¾“å…¥æ–‡ä»¶åç”ŸæˆåŸºæœ¬æ–‡ä»¶å (ç”¨äºæ–‡ä»¶å‘½å)
    input_path = Path(input_file)
    base_name = input_path.stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶åï¼Œå¦‚ "TL.CFE"
    
    # æ„å»ºè¾“å‡ºç›®å½•åç§°: Code_Name (e.g., 000510_SH_ä¸­è¯A500)
    # æ›¿æ¢åç§°ä¸­çš„éæ³•å­—ç¬¦
    import re
    safe_name = re.sub(r'[\\/*?:"<>|]', '_', data.name)
    safe_symbol = data.symbol.replace('.', '_')
    
    # å¦‚æœ symbol å’Œ name ç›¸åŒï¼Œåªç”¨ symbolï¼Œå¦åˆ™ symbol_name
    if safe_name == safe_symbol or safe_name == data.symbol:
        dir_name = safe_symbol.lower()
    else:
        dir_name = f"{safe_symbol}_{safe_name}".lower() # ä¿æŒå°å†™é£æ ¼ï¼Œè™½ç„¶ä¸­æ–‡ä¸ä¼šå˜å°å†™
    
    # åˆ›å»ºtickerå­ç›®å½•
    ticker_processed_dir = DATA_PROCESSED_DIR / dir_name
    ticker_output_dir = OUTPUT_DIR / dir_name
    ticker_processed_dir.mkdir(parents=True, exist_ok=True)
    ticker_output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¾“å‡ºè·¯å¾„
    processed_csv = ticker_processed_dir / f"{base_name}_processed.csv"
    merged_csv = ticker_processed_dir / f"{base_name}_merged.csv"
    strokes_csv = ticker_processed_dir / f"{base_name}_strokes.csv"
    merged_plot = ticker_output_dir / f"{base_name}_merged_kline.png"
    strokes_plot = ticker_output_dir / f"{base_name}_strokes.png"
    
    # Step 2: å¤„ç†åŸå§‹æ•°æ®ï¼Œæ·»åŠ Kçº¿çŠ¶æ€
    print(f"\n[Step 2/4] æ·»åŠ  K çº¿çŠ¶æ€æ ‡ç­¾...")
    from src.analysis import process_and_save
    process_and_save(data, str(processed_csv))
    
    # Step 3: K çº¿åˆå¹¶
    print(f"\n[Step 3/4] åˆå¹¶åŒ…å«å…³ç³»çš„ K çº¿...")
    from src.analysis.merging import apply_kline_merging
    apply_kline_merging(str(processed_csv), str(merged_csv), 
                        save_plot_path=str(merged_plot))
    
    # Step 4: åˆ†å‹è¯†åˆ«ä¸ç¬”è¿‡æ»¤
    print(f"\n[Step 4/4] è¯†åˆ«åˆ†å‹å¹¶ç”Ÿæˆæœ‰æ•ˆç¬”...")
    from src.analysis.fractals import process_strokes
    process_strokes(str(merged_csv), str(strokes_csv),
                    save_plot_path=str(strokes_plot))

    # Step 5: ç”Ÿæˆäº¤äº’å¼å›¾è¡¨
    print(f"\n[Step 5/5] ç”Ÿæˆäº¤äº’å¼ HTML å›¾è¡¨...")
    from src.analysis import ChartBuilder, compute_ema
    interactive_plot = ticker_output_dir / f"{base_name}_interactive.html"
    
    # é‡æ–°åŠ è½½æ•°æ®ä»¥è·å–ç»˜å›¾æ‰€éœ€çš„DataFrame
    import pandas as pd
    
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨åˆå¹¶åçš„æ•°æ®æ¥ç”»å›¾ï¼Œå› ä¸ºå®ƒæ›´å¹²å‡€
    # ä½†strokesæ˜¯åŸºäºåˆå¹¶åæ•°æ®çš„ç´¢å¼•ï¼Œæ‰€ä»¥æ˜¯å¯¹é½çš„
    merged_df = pd.read_csv(merged_csv)
    # è½¬æ¢ datetime
    merged_df['datetime'] = pd.to_datetime(merged_df['datetime'])
    
    # è¯»å– strokes
    strokes_df = pd.read_csv(strokes_csv)
    # è½¬æ¢ strokes ä¸º [(idx, type)] æ ¼å¼
    stroke_list = [
        (idx, row['valid_fractal']) 
        for idx, row in strokes_df.iterrows()
        if pd.notna(row['valid_fractal'])
    ]
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    merged_df['ema20'] = compute_ema(merged_df, 20)
    
    # ä½¿ç”¨ ChartBuilder æ„å»ºå›¾è¡¨
    chart = ChartBuilder(merged_df)
    chart.add_candlestick()
    chart.add_indicator('EMA20', merged_df['ema20'], '#FFA500')  # æ©™è‰²
    chart.add_strokes(stroke_list)
    chart.add_fractal_markers(stroke_list)
    
    # è®¾ç½®æ ‡é¢˜: Name [Symbol]
    chart_title = f"{data.name} [{data.symbol}]"
    chart.build(str(interactive_plot), title=chart_title)
    
    print("\n" + "=" * 60)
    print("æµæ°´çº¿å®Œæˆï¼")
    print("=" * 60)
    print("ç”Ÿæˆæ–‡ä»¶:")
    print(f"  CSV (data/processed/):")
    print(f"    - {processed_csv.name}  (å¸¦çŠ¶æ€æ ‡ç­¾çš„åŸå§‹Kçº¿)")
    print(f"    - {merged_csv.name}     (åˆå¹¶åçš„Kçº¿)")
    print(f"    - {strokes_csv.name}    (å¸¦ç¬”ç«¯ç‚¹æ ‡è®°çš„æœ€ç»ˆç»“æœ)")
    print(f"  å›¾è¡¨ (output/):")
    print(f"    - {merged_plot.name}  (åˆå¹¶åKçº¿å›¾)")
    print(f"    - {strokes_plot.name}       (ç¬”ç«¯ç‚¹æ ‡è®°å›¾)")
    print(f"    - {interactive_plot.name}   (äº¤äº’å¼HTMLå›¾è¡¨) ğŸ†•")


if __name__ == "__main__":
    # é»˜è®¤æ•°æ®æ–‡ä»¶
    DEFAULT_FILE = "data/raw/TB10Y.WI.xlsx"
    input_files = []
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æˆ–äº¤äº’å¼é€‰æ‹©
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œå‚æ•°ä¼ å…¥å¤šä¸ªæ–‡ä»¶
        input_files = sys.argv[1:]
    elif sys.stdin.isatty():
        # äº¤äº’å¼ç»ˆç«¯ï¼Œè®©ç”¨æˆ·é€‰æ‹©
        input_files = select_file_interactive()
    else:
        # éäº¤äº’æ¨¡å¼ï¼ˆå¦‚ agent è°ƒç”¨ï¼‰ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶
        print(f"éäº¤äº’æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶: {DEFAULT_FILE}")
        input_files = [DEFAULT_FILE]
    
    # æ‰¹é‡å¤„ç†
    total = len(input_files)
    for i, f in enumerate(input_files, 1):
        if total > 1:
            print("\n" + "#" * 60)
            print(f"æ­£åœ¨å¤„ç†ç¬¬ {i}/{total} ä¸ªæ–‡ä»¶: {Path(f).name}")
            print("#" * 60)
        
        try:
            main(f)
        except Exception as e:
            print(f"\nâŒ å¤„ç†å¤±è´¥ {f}: {e}")
            # å¦‚æœæ˜¯æ‰¹é‡å¤„ç†ï¼Œä¸è¦å› ä¸ºä¸€ä¸ªå¤±è´¥å°±é€€å‡ºå…¨éƒ¨ï¼ˆé™¤éæ˜¯ä¸¥é‡é”™è¯¯ï¼‰
            if total == 1:
                raise
